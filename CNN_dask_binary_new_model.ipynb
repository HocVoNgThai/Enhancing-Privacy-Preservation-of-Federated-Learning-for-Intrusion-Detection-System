{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# file_path = \"Processed_Data/Mapped_Dataset.csv\"\n",
    "# file_path=\"C:/Users/hoang/FileCSV_DACN_2025/Benign_ddos_dos_Mapped_Dataset.csv\"\n",
    "file_path = \"/mnt/d/DoAnChuyenNganh_Train/data/shuffled_remapping_dataset_2type.csv\"\n",
    "\n",
    "df = dk.read_csv(file_path)\n",
    "# df = df.drop(columns=['Variance', 'Weight'])\n",
    "print(df.dtypes)\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d285cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# labels = ['BenignTraffic', 'DDoS-ICMP_Flood', 'DDoS-PSHACK_Flood', 'DDoS-RSTFINFlood', 'DDoS-SYN_Flood', \n",
    "#                    'DDoS-SynonymousIP_Flood', 'DDoS-TCP_Flood', 'DDoS-UDP_Flood', 'DoS-SYN_Flood', 'DoS-TCP_Flood', 'DoS-UDP_Flood']\n",
    "# Đếm số lượng mỗi nhãn\n",
    "label_counts = df['label'].value_counts().compute()\n",
    "print(label_counts)\n",
    "labels = [\"Benign\", \"Malicious\"]\n",
    "# Vẽ biểu đồ cột\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.bar(labels, label_counts.values, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"Nhãn (Classes)\")\n",
    "plt.ylabel(\"Số lượng mẫu (Frequency)\")\n",
    "plt.title(\"Tỷ lệ nhãn trong Dataset\")\n",
    "plt.xticks(range(len(labels)) ,labels, rotation =45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070939d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global var \n",
    "batch_size = 512\n",
    "ratio_test_all = 0.20\n",
    "\n",
    "from dask_ml.model_selection import train_test_split \n",
    "\n",
    "# chia train test ratio 0.8:0.2 & random \n",
    "train_df, val_test_df = train_test_split(df, test_size=ratio_test_all, random_state=42)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.75, random_state=42)\n",
    "\n",
    "# # load từng batch\n",
    "def dask_to_tf_dataset(dask_df, batch_size): \n",
    "    def generator():\n",
    "        for batch in dask_df.to_delayed():\n",
    "            batch = batch.compute()  \n",
    "            if batch.empty:\n",
    "                continue\n",
    "\n",
    "            X = batch.drop(columns='label').values.astype(np.float32)\n",
    "            y = batch['label'].values.astype(np.int32)  # nhị phân: 0 hoặc 1\n",
    "\n",
    "            num_splits = max(1, len(X) // batch_size)\n",
    "            X_batches = np.array_split(X, num_splits)\n",
    "            y_batches = np.array_split(y, num_splits)\n",
    "\n",
    "            for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "                yield X_batch, y_batch\n",
    "\n",
    "    output_signature = ( \n",
    "        tf.TensorSpec(shape=(None, 46), dtype=tf.float32), \n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32),  # không phải one-hot nữa\n",
    "    )\n",
    "    \n",
    "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = dask_to_tf_dataset(train_df, 512).repeat()\n",
    "test_gen = dask_to_tf_dataset(test_df, 512)\n",
    "val_gen = dask_to_tf_dataset(val_df, 512).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf88004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import sys, os\n",
    "# shape\n",
    "features, labels = next(iter(train_gen))\n",
    "input_shape = (features.shape[1], 1)\n",
    "# output_shape = labels.shape[1]\n",
    "\n",
    "print(f\"Input Shape: {input_shape}\")\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "# Định nghĩa mô hình CNN\n",
    "# VGG, ...\n",
    "# Conv2D, tabular, ...\n",
    "# HE, tính tương thích của HE với CNN\n",
    "# Tính chất data in, out; Học tăng cường\n",
    "start_time = datetime.now()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    #layers.Input(shape=input_shape),\n",
    "    #layers.Conv1D(filters=128, kernel_size=7, padding=\"same\", activation=\"relu\"),\n",
    "    #layers.BatchNormalization(),\n",
    "    #layers.Conv1D(filters=128, kernel_size=7, padding=\"same\", activation=\"relu\"),\n",
    "    #layers.BatchNormalization(),\n",
    "    #layers.MaxPooling1D(pool_size=2),\n",
    "    #layers.Dropout(0.5),\n",
    "    #layers.Flatten(),\n",
    "    #layers.Dense(128, activation='relu'),\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv1D(filters=128, kernel_size=3, padding=\"same\", strides=1), # activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)\n",
    "    layers.BatchNormalization(),\n",
    "    # layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", strides=1),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    # layers.Dropout(0.25),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "opt = SGD(learning_rate=0.01, momentum=0.8)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "os.makedirs(\"log_mono\", exist_ok=True)\n",
    "# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "csv_logger = CSVLogger(\"log_mono/\"+ datetime.now().strftime(\"%d--%m--%Y___%Hh--%Mp\")+\".csv\" , append=True)\n",
    "model.fit(train_gen, epochs=50, validation_data=val_gen, validation_steps= 498 , steps_per_epoch=7968, verbose = 1, callbacks=[csv_logger])\n",
    "\n",
    "# 498/7968\n",
    "\n",
    "\n",
    "end_time = datetime.now()\n",
    "simulated_time = end_time - start_time\n",
    "model_name = \"model/cnn_model_2-0_batch512_\" + datetime.now().strftime(\"%d--%m--%Y___%Hh--%Mp\")+\".keras\"\n",
    "# Lưu mô hình\n",
    "model.save(model_name)\n",
    "\n",
    "print(f\"Simulated time: {simulated_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "#input_model = \"saved_model/cnn_model_2-0_batch512_\" + datetime.now().strftime(\"%Hh%Mp__%d-%m-%Y\")+\".keras\"\n",
    "model = load_model(model_name)\n",
    "\n",
    "output = model.evaluate(test_gen, steps = 1493)\n",
    "print(f'Loss: {output[0]} Acc: {output[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31afa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#input_model = \"/home/hoangvn/Enhancing_PP_of_FL_for_IDS/saved_model/cnn_model_2-0_batch512_10h07p__13-04-2025.keras\"\n",
    "model = load_model(model_name)\n",
    "#model = load_model(\"saved_model/cnn_model_2-0_batch512_20h37p__06-05-2025.keras\")\n",
    "# Tính số hàng thật sự trong test_df\n",
    "num_samples_test = test_df.shape[0].compute()\n",
    "# Tính số batch\n",
    "num_batches_test = int(np.ceil(num_samples_test / batch_size))\n",
    "print(\"Batch test: \", num_batches_test)\n",
    "\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for X_batch, y_batch in test_gen.take(num_batches_test):\n",
    "    y_true_all.extend(y_batch.numpy().flatten())\n",
    "\n",
    "    y_pred_prob = model.predict(X_batch, verbose=0)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    y_pred_all.extend(y_pred)\n",
    "\n",
    "# Tính metric\n",
    "precision = precision_score(y_true_all, y_pred_all, average='binary')\n",
    "recall = recall_score(y_true_all, y_pred_all, average='binary')\n",
    "f1 = f1_score(y_true_all, y_pred_all, average='binary')\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1-Score: \", f1)\n",
    "\n",
    "param_names = ['Precision', 'Recall', 'F1-Score']\n",
    "array = [precision, recall, f1]\n",
    "\n",
    "x = np.arange(len(param_names))\n",
    "width = 0.2  # Độ rộng của mỗi cột\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(param_names, array, color=['blue', 'green', 'red'])\n",
    "\n",
    "# Cấu hình trục và nhãn\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall, and F1-Score\")\n",
    "plt.ylim(0, 1)  # Giá trị từ 0 đến 1\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a753740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Tạo ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "attack_types =['BenignTraffic', 'MaliciouTraffic']\n",
    "# Vẽ heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(cm.shape[0]), yticklabels=range(cm.shape[0))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=attack_types, yticklabels=attack_types)\n",
    "\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "metrics = []\n",
    "num_classes = len(attack_types)\n",
    "\n",
    "# Duyệt từng lớp để tính TP, FP, TN, FN\n",
    "for i in range(num_classes):\n",
    "    TP = cm[i, i]\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    \n",
    "    metrics.append([attack_types[i], TP, FP, TN, FN])\n",
    "\n",
    "# Chuyển thành DataFrame\n",
    "df_metrics = pd.DataFrame(metrics, columns=[\"Attack_Types\", \"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "# Vẽ biểu đồ\n",
    "df_metrics.set_index(\"Attack_Types\").plot(kind=\"bar\", figsize=(12, 5), colormap=\"viridis\")\n",
    "\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"TP, FP, TN, FN for Each Class\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend([\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09518109-89e3-4f1f-915a-7341418de65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Đọc log từ file CSV\n",
    "log_df = pd.read_csv('log_mono/19h56p__06-05-2025.csv')  # Đổi tên file nếu cần\n",
    "\n",
    "epochs = range(1, len(log_df) + 1)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs, log_df['accuracy'], 'b-', label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, log_df['loss'], 'r-', label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Validation Accuracy\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, log_df['val_accuracy'], 'g-', label='Validation Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Validation Loss\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs, log_df['val_loss'], 'm-', label='Validation Loss')\n",
    "plt.title('Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
