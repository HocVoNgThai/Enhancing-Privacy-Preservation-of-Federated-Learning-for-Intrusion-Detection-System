{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f1016c2-e68c-4c3c-8004-39de281d72b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 125.62 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/th/miniconda3/envs/tf/lib/python3.9/site-packages/dask/dataframe/core.py:8153: UserWarning: Insufficient elements for `head`. 11000000 elements requested, only 226716 elements available. Try passing larger `npartitions` to `head`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "input_file = \"balanced_dataset_final.csv\" \n",
    "output_file = \"remapping_dataset.csv\"\n",
    "# Đọc bằng Dask cho file lớn\n",
    "ddf = dd.read_csv(input_file)\n",
    "\n",
    "# Remap labels\n",
    "ddf['label'] = ddf['label'].map({0:0, 4:1}, meta=('label', 'int64'))\n",
    "\n",
    "# Shuffle (Dask không hỗ trợ shuffle trực tiếp, cần workaround)\n",
    "ddf = ddf.sample(frac=1, random_state=42)\n",
    "\n",
    "# Lưu kết quả\n",
    "with ProgressBar():\n",
    "    ddf.to_csv(output_file, single_file=True, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fb65d6-539c-422e-9c49-25f8de37f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu: 11098198\n",
      "Phân bố label:\n",
      "label\n",
      "0     1098195\n",
      "1    10000003\n",
      "Name: count, dtype: int64\n",
      "Chuỗi liên tiếp dài nhất trong 11 triệu mẫu đầu: 226716\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Kiểm tra dataset sau khi xử lý\n",
    "\"\"\"\n",
    "#df = dk.read_csv(\"single_file.csv\")\n",
    "    \n",
    "# Tính tổng số mẫu\n",
    "total_samples = ddf.shape[0].compute()\n",
    "print(f\"Tổng số mẫu: {total_samples}\")\n",
    "    \n",
    "# Tính phân bố label\n",
    "label_counts = ddf['label'].value_counts().compute()\n",
    "print(\"Phân bố label:\")\n",
    "print(label_counts.sort_index())\n",
    "    \n",
    "# Kiểm tra số lượng label liên tiếp\n",
    "df_small = ddf.head(11000000)\n",
    "labels = df_small['label'].values\n",
    "max_consecutive = current = 1  \n",
    "\n",
    "for i in range(1, len(labels)):\n",
    "    if labels[i] == labels[i-1]:\n",
    "        current += 1\n",
    "        max_consecutive = max(max_consecutive, current)\n",
    "    else:\n",
    "        current = 1  # Reset bộ đếm khi label thay đổi\n",
    "\n",
    "print(f\"Chuỗi liên tiếp dài nhất trong 11 triệu mẫu đầu: {max_consecutive}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586e21e2-0c69-48b0-ae0d-632859d5e262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 10:13:37.022614: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-31 10:13:37.065315: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748661217.078486     544 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748661217.082586     544 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748661217.102713     544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748661217.102729     544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748661217.102730     544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748661217.102730     544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-31 10:13:37.106603: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3102\n",
      "flow_duration      float64\n",
      "Header_Length      float64\n",
      "Protocol Type      float64\n",
      "Duration           float64\n",
      "Rate               float64\n",
      "Srate              float64\n",
      "Drate              float64\n",
      "fin_flag_number    float64\n",
      "syn_flag_number    float64\n",
      "rst_flag_number    float64\n",
      "psh_flag_number    float64\n",
      "ack_flag_number    float64\n",
      "ece_flag_number    float64\n",
      "cwr_flag_number    float64\n",
      "ack_count          float64\n",
      "syn_count          float64\n",
      "fin_count          float64\n",
      "urg_count          float64\n",
      "rst_count          float64\n",
      "HTTP               float64\n",
      "HTTPS              float64\n",
      "DNS                float64\n",
      "Telnet             float64\n",
      "SMTP               float64\n",
      "SSH                float64\n",
      "IRC                float64\n",
      "TCP                float64\n",
      "UDP                float64\n",
      "DHCP               float64\n",
      "ARP                float64\n",
      "ICMP               float64\n",
      "IPv                float64\n",
      "LLC                float64\n",
      "Tot sum            float64\n",
      "Min                float64\n",
      "Max                float64\n",
      "AVG                float64\n",
      "Std                float64\n",
      "Tot size           float64\n",
      "IAT                float64\n",
      "Number             float64\n",
      "Magnitue           float64\n",
      "Radius             float64\n",
      "Covariance         float64\n",
      "Variance           float64\n",
      "Weight             float64\n",
      "label                int64\n",
      "dtype: object\n",
      "   flow_duration  Header_Length  Protocol Type  Duration         Rate  \\\n",
      "0       0.000000          54.00           6.00     64.00     0.773694   \n",
      "1       0.088121       33504.00          17.00     64.00  7601.095827   \n",
      "2       0.000000           0.00           1.00     64.00   267.732925   \n",
      "3       0.000000          54.00           6.00     64.00    30.296142   \n",
      "4       0.000000          54.00           6.00     64.00    23.850787   \n",
      "5       0.000000           0.00           1.00     64.00    17.337781   \n",
      "6       0.000000           0.00           1.00     64.00    21.761122   \n",
      "7       0.194625       40486.50          14.92     88.83  5554.726581   \n",
      "8       0.120335       35061.26          16.89     65.23  5848.139166   \n",
      "9       0.000000          53.46           5.94     63.36    31.865255   \n",
      "\n",
      "         Srate  Drate  fin_flag_number  syn_flag_number  rst_flag_number  ...  \\\n",
      "0     0.773694    0.0              0.0              0.0              0.0  ...   \n",
      "1  7601.095827    0.0              0.0              0.0              0.0  ...   \n",
      "2   267.732925    0.0              0.0              0.0              0.0  ...   \n",
      "3    30.296142    0.0              0.0              0.0              0.0  ...   \n",
      "4    23.850787    0.0              0.0              0.0              0.0  ...   \n",
      "5    17.337781    0.0              0.0              0.0              0.0  ...   \n",
      "6    21.761122    0.0              0.0              0.0              0.0  ...   \n",
      "7  5554.726581    0.0              0.0              0.0              0.0  ...   \n",
      "8  5848.139166    0.0              0.0              0.0              0.0  ...   \n",
      "9    31.865255    0.0              0.0              0.0              0.0  ...   \n",
      "\n",
      "        Std  Tot size           IAT  Number   Magnitue    Radius  Covariance  \\\n",
      "0  0.000000     54.00  8.307591e+07     9.5  10.392305  0.000000    0.000000   \n",
      "1  0.000000     50.00  8.310662e+07     9.5  10.000000  0.000000    0.000000   \n",
      "2  0.000000     42.00  8.312889e+07     9.5   9.165151  0.000000    0.000000   \n",
      "3  0.000000     54.00  8.307638e+07     9.5  10.392305  0.000000    0.000000   \n",
      "4  0.000000     54.00  8.303401e+07     9.5  10.392305  0.000000    0.000000   \n",
      "5  0.000000     42.00  8.314939e+07     9.5   9.165151  0.000000    0.000000   \n",
      "6  0.000000     42.00  8.312811e+07     9.5   9.165151  0.000000    0.000000   \n",
      "7  1.452421     52.60  8.310186e+07     9.5  10.322636  1.970498   10.688830   \n",
      "8  1.565612     50.76  8.309858e+07     9.5  10.061429  2.217821   20.647072   \n",
      "9  0.149099     54.06  8.303412e+07     9.5  10.396174  0.211311    0.224905   \n",
      "\n",
      "   Variance  Weight  label  \n",
      "0      0.00  141.55      1  \n",
      "1      0.00  141.55      1  \n",
      "2      0.00  141.55      1  \n",
      "3      0.00  141.55      1  \n",
      "4      0.00  141.55      1  \n",
      "5      0.00  141.55      1  \n",
      "6      0.00  141.55      1  \n",
      "7      0.20  141.55      1  \n",
      "8      0.12  141.55      1  \n",
      "9      0.10  141.55      1  \n",
      "\n",
      "[10 rows x 47 columns]\n",
      "flow_duration      float64\n",
      "Header_Length      float64\n",
      "Protocol Type      float64\n",
      "Duration           float64\n",
      "Rate               float64\n",
      "Srate              float64\n",
      "Drate              float64\n",
      "fin_flag_number    float64\n",
      "syn_flag_number    float64\n",
      "rst_flag_number    float64\n",
      "psh_flag_number    float64\n",
      "ack_flag_number    float64\n",
      "ece_flag_number    float64\n",
      "cwr_flag_number    float64\n",
      "ack_count          float64\n",
      "syn_count          float64\n",
      "fin_count          float64\n",
      "urg_count          float64\n",
      "rst_count          float64\n",
      "HTTP               float64\n",
      "HTTPS              float64\n",
      "DNS                float64\n",
      "Telnet             float64\n",
      "SMTP               float64\n",
      "SSH                float64\n",
      "IRC                float64\n",
      "TCP                float64\n",
      "UDP                float64\n",
      "DHCP               float64\n",
      "ARP                float64\n",
      "ICMP               float64\n",
      "IPv                float64\n",
      "LLC                float64\n",
      "Tot sum            float64\n",
      "Min                float64\n",
      "Max                float64\n",
      "AVG                float64\n",
      "Std                float64\n",
      "Tot size           float64\n",
      "IAT                float64\n",
      "Number             float64\n",
      "Magnitue           float64\n",
      "Radius             float64\n",
      "Covariance         float64\n",
      "Variance           float64\n",
      "Weight             float64\n",
      "label                int64\n",
      "dtype: object\n",
      "3102\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mnpartitions)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print(df.head(20))\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/dask_expr/_collection.py:3296\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_parquet\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3294\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask_expr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 3296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/dask_expr/io/parquet.py:653\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, name_function, filesystem, engine, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m     out \u001b[38;5;241m=\u001b[39m new_collection(\n\u001b[1;32m    633\u001b[0m         ToParquet(\n\u001b[1;32m    634\u001b[0m             df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n\u001b[1;32m    650\u001b[0m     )\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[0;32m--> 653\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# Invalidate the filesystem listing cache for the output path after write.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# We do this before returning, even if `compute=False`. This helps ensure\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# that reading files that were just written succeeds.\u001b[39;00m\n\u001b[1;32m    658\u001b[0m fs\u001b[38;5;241m.\u001b[39minvalidate_cache(path)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/dask_expr/_collection.py:477\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[0;34m(self, fuse, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    476\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDaskMethodsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/dask/base.py:376\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dk\n",
    "import tensorflow as tf\n",
    "file_path = \"remapping_dataset.csv\"\n",
    "out_path =   \"shuffled_remapping_df_2type/\"\n",
    "\n",
    "df = dk.read_csv(file_path, blocksize=\"10MB\")\n",
    "# df = df.drop(columns=['Variance', 'Weight'])\n",
    "print(df.npartitions)\n",
    "print(df.dtypes)\n",
    "print(df.head(10))\n",
    "from dask_ml.model_selection import train_test_split \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def shuffle_dask_dataframe(df, random_state=None):\n",
    "    return (\n",
    "        df.map_partitions(\n",
    "            lambda part: part.assign(__shuffle_key=np.random.RandomState(random_state).random(len(part)))\n",
    "        )\n",
    "        .shuffle('__shuffle_key')\n",
    "        .drop(columns='__shuffle_key')\n",
    "    )\n",
    "    \n",
    "df = shuffle_dask_dataframe(df)\n",
    "\n",
    "print(df.dtypes)\n",
    "print(df.npartitions)\n",
    "# print(df.head(20))\n",
    "df.to_parquet(out_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7000f9-9b0d-4a1f-97a0-6616d2c3aa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
