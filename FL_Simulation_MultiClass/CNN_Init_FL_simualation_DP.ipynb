{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532a9bb-0cbe-49bb-b22f-155e520aaaa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:40:47.781217: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-23 22:40:47.812693: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750693247.834236  229100 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750693247.840030  229100 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750693247.866203  229100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750693247.866225  229100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750693247.866226  229100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750693247.866227  229100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-23 22:40:47.875506: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FL_Data/file1', 'FL_Data/file2', 'FL_Data/file3']\n",
      "flow_duration      float64\n",
      "Header_Length      float64\n",
      "Protocol Type      float64\n",
      "Duration           float64\n",
      "Rate               float64\n",
      "Srate              float64\n",
      "Drate              float64\n",
      "fin_flag_number    float64\n",
      "syn_flag_number    float64\n",
      "rst_flag_number    float64\n",
      "psh_flag_number    float64\n",
      "ack_flag_number    float64\n",
      "ece_flag_number    float64\n",
      "cwr_flag_number    float64\n",
      "ack_count          float64\n",
      "syn_count          float64\n",
      "fin_count          float64\n",
      "urg_count          float64\n",
      "rst_count          float64\n",
      "HTTP               float64\n",
      "HTTPS              float64\n",
      "DNS                float64\n",
      "Telnet             float64\n",
      "SMTP               float64\n",
      "SSH                float64\n",
      "IRC                float64\n",
      "TCP                float64\n",
      "UDP                float64\n",
      "DHCP               float64\n",
      "ARP                float64\n",
      "ICMP               float64\n",
      "IPv                float64\n",
      "LLC                float64\n",
      "Tot sum            float64\n",
      "Min                float64\n",
      "Max                float64\n",
      "AVG                float64\n",
      "Std                float64\n",
      "Tot size           float64\n",
      "IAT                float64\n",
      "Number             float64\n",
      "Magnitue           float64\n",
      "Radius             float64\n",
      "Covariance         float64\n",
      "Variance           float64\n",
      "Weight             float64\n",
      "label                int32\n",
      "dtype: object\n",
      "Feature Len:  46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750693251.555995  229100 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['server_0']\n",
      "['client_0', 'client_1', 'client_2']\n",
      "multiclass_FL_log/Month06-Day23-22h-40p\n",
      "Train steps:  10675\n",
      "Val steps:  665\n",
      "Test steps:  2002\n",
      "Train steps:  7478\n",
      "Val steps:  467\n",
      "Test steps:  1401\n",
      "Train steps:  8523\n",
      "Val steps:  532\n",
      "Test steps:  1597\n",
      "====================================== Đang chạy Iteration 1 ======================================\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750693261.461077  229173 service.cc:152] XLA service 0x7f5ae8003640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750693261.461123  229173 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "I0000 00:00:1750693261.476593  229173 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1750693261.605908  229174 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-06-23 22:41:04.236286: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8019/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8284 - loss: 0.7706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:41:55.626081: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n",
      "2025-06-23 22:41:55.689348: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-06-23 22:41:55.702498: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7985/8523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8298 - loss: 0.7804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:41:56.072954: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:41:56.215630: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8318/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.8314 - loss: 0.7575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:41:57.473526: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8354/8523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 0.7640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:41:58.037654: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-06-23 22:41:58.093068: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n",
      "2025-06-23 22:41:58.430762: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8531/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 0.7486"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:00.886503: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:01.228451: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8533/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 0.7485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:01.390451: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8554/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8337 - loss: 0.7476"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:02.316440: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8758/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8356 - loss: 0.7394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:05.031364: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:05.118288: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:05.182830: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 292 bytes spill stores, 292 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8794/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8359 - loss: 0.7379"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:05.273352: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 724 bytes spill stores, 788 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8904/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8369 - loss: 0.7336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:06.762468: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9022/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8379 - loss: 0.7291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:07.640577: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:07.645236: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9131/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8388 - loss: 0.7249"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:09.169459: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:09.238173: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9176/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8392 - loss: 0.7232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:09.457198: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9584/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8426 - loss: 0.7084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:11.719218: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9629/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8429 - loss: 0.7068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:11.962469: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:11.975566: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:12.000101: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9713/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8436 - loss: 0.7039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:12.457216: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:12.503103: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9752/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8439 - loss: 0.7025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:13.138280: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:13.235772: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:13.315890: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:13.400302: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:13.484143: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:13.566117: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:13.648295: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:13.728288: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:13.807349: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9754/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8439 - loss: 0.7025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:13.888446: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:13.969353: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:14.050605: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9772/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8440 - loss: 0.7018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:14.143822: W external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:1369] AutotunerUtil::AddResult already existed: <key model='CUDA: 8.9, Cores: 20, GPU clock: 2.055 GHz, Memory bandwidth: 192 GB/s, L2 cache: 24 MB', hlo='{\n",
      "  tmp_0 = f16[258,128]{1,0} parameter(0)\n",
      "  tmp_1 = f32[128,5]{1,0} parameter(1)\n",
      "  tmp_2 = f16[128,5]{1,0} convert(f32[128,5]{1,0} tmp_1)\n",
      "  ROOT tmp_3 = f16[258,5]{1,0} dot(f16[258,128]{1,0} tmp_0, f16[128,5]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={0}, frontend_attributes={grad_x=\"false\",grad_y=\"false\"}\n",
      "}'>\n",
      "2025-06-23 22:42:14.243075: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:14.246620: W external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:1369] AutotunerUtil::AddResult already existed: <key model='CUDA: 8.9, Cores: 20, GPU clock: 2.055 GHz, Memory bandwidth: 192 GB/s, L2 cache: 24 MB', hlo='{\n",
      "  tmp_0 = f32[704,128]{1,0} parameter(1)\n",
      "  tmp_1 = f16[704,128]{1,0} convert(f32[704,128]{1,0} tmp_0)\n",
      "  tmp_2 = f16[258,1,11,64]{3,2,1,0} parameter(0)\n",
      "  tmp_3 = f16[258,704]{1,0} bitcast(f16[258,1,11,64]{3,2,1,0} tmp_2)\n",
      "  tmp_4 = f16[128,258]{0,1} dot(f16[704,128]{1,0} tmp_1, f16[258,704]{1,0} tmp_3), lhs_contracting_dims={0}, rhs_contracting_dims={1}\n",
      "  ROOT tmp_5 = f16[258,128]{1,0} bitcast(f16[128,258]{0,1} tmp_4)\n",
      "}'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10663/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8504 - loss: 0.6730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:21.060244: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:21.203715: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:21.313689: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:21.965001: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:22.618465: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:22.773060: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:23.044516: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.146760: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.231993: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.313283: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.393511: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.481002: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.564451: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.649634: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.731335: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.815883: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.899960: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:23.983707: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.067716: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.147845: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.232508: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.312330: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.395328: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.493602: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.576383: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.659405: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.740017: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10667/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8504 - loss: 0.6729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:24.823142: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.912372: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.993002: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:24.997821: W external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:1369] AutotunerUtil::AddResult already existed: <key model='CUDA: 8.9, Cores: 20, GPU clock: 2.055 GHz, Memory bandwidth: 192 GB/s, L2 cache: 24 MB', hlo='{\n",
      "  tmp_0 = f16[262,128]{1,0} parameter(0)\n",
      "  tmp_1 = f32[128,5]{1,0} parameter(1)\n",
      "  tmp_2 = f16[128,5]{1,0} convert(f32[128,5]{1,0} tmp_1)\n",
      "  ROOT tmp_3 = f16[262,5]{1,0} dot(f16[262,128]{1,0} tmp_0, f16[128,5]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={0}, frontend_attributes={grad_x=\"false\",grad_y=\"false\"}\n",
      "}'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10669/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8504 - loss: 0.6728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:42:25.102325: W external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:1369] AutotunerUtil::AddResult already existed: <key model='CUDA: 8.9, Cores: 20, GPU clock: 2.055 GHz, Memory bandwidth: 192 GB/s, L2 cache: 24 MB', hlo='{\n",
      "  tmp_0 = f32[704,128]{1,0} parameter(1)\n",
      "  tmp_1 = f16[704,128]{1,0} convert(f32[704,128]{1,0} tmp_0)\n",
      "  tmp_2 = f16[262,1,11,64]{3,2,1,0} parameter(0)\n",
      "  tmp_3 = f16[262,704]{1,0} bitcast(f16[262,1,11,64]{3,2,1,0} tmp_2)\n",
      "  tmp_4 = f16[128,262]{0,1} dot(f16[704,128]{1,0} tmp_1, f16[262,704]{1,0} tmp_3), lhs_contracting_dims={0}, rhs_contracting_dims={1}\n",
      "  ROOT tmp_5 = f16[262,128]{1,0} bitcast(f16[128,262]{0,1} tmp_4)\n",
      "}'>\n",
      "2025-06-23 22:42:28.274193: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:28.284620: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:28.284724: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:28.521957: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:28.549024: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:28.642790: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 808 bytes spill stores, 716 bytes spill loads\n",
      "\n",
      "2025-06-23 22:42:29.083701: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:29.191198: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:29.273201: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:29.358406: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:29.449718: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:29.533715: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:29.615335: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:29.714178: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:29.795284: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:29.881401: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:29.965341: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.052606: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.133428: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.214177: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.216764: W external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:1369] AutotunerUtil::AddResult already existed: <key model='CUDA: 8.9, Cores: 20, GPU clock: 2.055 GHz, Memory bandwidth: 192 GB/s, L2 cache: 24 MB', hlo='{\n",
      "  tmp_0 = f32[704,128]{1,0} parameter(1)\n",
      "  tmp_1 = f16[704,128]{1,0} convert(f32[704,128]{1,0} tmp_0)\n",
      "  tmp_2 = f16[261,1,11,64]{3,2,1,0} parameter(0)\n",
      "  tmp_3 = f16[261,704]{1,0} bitcast(f16[261,1,11,64]{3,2,1,0} tmp_2)\n",
      "  tmp_4 = f16[128,261]{0,1} dot(f16[704,128]{1,0} tmp_1, f16[261,704]{1,0} tmp_3), lhs_contracting_dims={0}, rhs_contracting_dims={1}\n",
      "  ROOT tmp_5 = f16[261,128]{1,0} bitcast(f16[128,261]{0,1} tmp_4)\n",
      "}'>\n",
      "2025-06-23 22:42:30.297059: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.387030: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.467514: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.563493: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.648631: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.731511: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.812498: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.894245: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-23 22:42:30.910412: W external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:1369] AutotunerUtil::AddResult already existed: <key model='CUDA: 8.9, Cores: 20, GPU clock: 2.055 GHz, Memory bandwidth: 192 GB/s, L2 cache: 24 MB', hlo='{\n",
      "  tmp_0 = f16[261,128]{1,0} parameter(0)\n",
      "  tmp_1 = f32[128,5]{1,0} parameter(1)\n",
      "  tmp_2 = f16[128,5]{1,0} convert(f32[128,5]{1,0} tmp_1)\n",
      "  ROOT tmp_3 = f16[261,5]{1,0} dot(f16[261,128]{1,0} tmp_0, f16[128,5]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={0}, frontend_attributes={grad_x=\"false\",grad_y=\"false\"}\n",
      "}'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7478/7478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 12ms/step - accuracy: 0.8149 - loss: 0.8271 - val_accuracy: 0.9511 - val_loss: 0.1638\n",
      "Epoch 2/5\n",
      "\u001b[1m8523/8523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 11ms/step - accuracy: 0.8351 - loss: 0.7568 - val_accuracy: 0.9512 - val_loss: 0.1704\n",
      "\u001b[1m 518/7478\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 12ms/step - accuracy: 0.9526 - loss: 0.1628Epoch 2/5\n",
      "\u001b[1m10675/10675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 10ms/step - accuracy: 0.8505 - loss: 0.6726 - val_accuracy: 0.9528 - val_loss: 0.1432\n",
      "Epoch 2/5\n",
      "\u001b[1m7478/7478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 8ms/step - accuracy: 0.9506 - loss: 0.1569 - val_accuracy: 0.9536 - val_loss: 0.1311\n",
      "Epoch 3/5\n",
      "\u001b[1m1494/7478\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.9527 - loss: 0.1334"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import dask.dataframe as dk\n",
    "import tensorflow as tf\n",
    "import io\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Bật mixed precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "# Tắt một số cảnh báo không cần thiết từ TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "input_files = [f\"file{i+1}\" for i in range(3)]\n",
    "temp_dir = \"FL_Data/\"\n",
    "input_files = [temp_dir + output_file for output_file in input_files]\n",
    "print(input_files)\n",
    "\n",
    "df = [dk.read_parquet(file) for file in input_files]\n",
    "print(df[1].dtypes)\n",
    "\n",
    "batch_size = 256\n",
    "ratio_test_all = 0.2\n",
    "features_len = len(df[1].columns) - 1\n",
    "print(\"Feature Len: \", features_len)\n",
    "\n",
    "train_dfs = []\n",
    "val_dfs = []\n",
    "test_dfs = []\n",
    "for dff in df:\n",
    "    train_df, val_test_df = dff.random_split([1 - ratio_test_all, ratio_test_all])\n",
    "    test_df, val_df = val_test_df.random_split([1 - 0.25, 0.25])\n",
    "    train_dfs.append(train_df)\n",
    "    val_dfs.append(val_df)\n",
    "    test_dfs.append(test_df)\n",
    "\n",
    "def dask_to_tf_dataset(dask_df, batch_size):\n",
    "    def generator():\n",
    "        for batch in dask_df.to_delayed():\n",
    "            batch = batch.compute()\n",
    "            if batch.empty:\n",
    "                continue\n",
    "            X = batch.drop(columns=['label']).values.astype(np.float32)\n",
    "            y = batch['label'].values.astype(np.int32)\n",
    "            num_splits = max(1, len(X) // batch_size)\n",
    "            X_batches = np.array_split(X, num_splits)\n",
    "            y_batches = np.array_split(y, num_splits)\n",
    "            for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "                yield X_batch, y_batch\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(None, features_len), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    )\n",
    "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_gens = [dask_to_tf_dataset(train_df, batch_size).repeat() for train_df in train_dfs]\n",
    "val_gens = [dask_to_tf_dataset(val_df, batch_size).repeat() for val_df in val_dfs]\n",
    "test_gens = [dask_to_tf_dataset(test_df, batch_size).repeat() for test_df in test_dfs]\n",
    "\n",
    "from server import Server\n",
    "from client import Client\n",
    "import datetime\n",
    "import tenseal as ts\n",
    "\n",
    "num_servers = 1\n",
    "num_clients = 3\n",
    "\n",
    "stepsPerEpoch_Clients = [int(np.ceil(train_dfs[index].shape[0].compute()) / batch_size) for index in range(num_clients)]\n",
    "stepsValidate_Clients = [int(np.ceil(val_dfs[index].shape[0].compute()) / batch_size) for index in range(num_clients)]\n",
    "stepsTest_Clients = [int(np.ceil(test_dfs[index].shape[0].compute()) / batch_size) for index in range(num_clients)]\n",
    "\n",
    "active_servers_list = ['server_' + str(i) for i in range(num_servers)]\n",
    "active_clients_list = ['client_' + str(i) for i in range(num_clients)]\n",
    "print(active_servers_list)\n",
    "print(active_clients_list)\n",
    "\n",
    "\n",
    "agents_dict = {}\n",
    "serverObjects = {server_name: Server(server_name=server_name, active_clients_list=active_clients_list)\n",
    "                 for server_name in active_servers_list}\n",
    "\n",
    "clientObjects = {client_name: Client(client_name, train_gens[clientID], val_gens[clientID], test_gens[clientID],\n",
    "                                     stepsPerEpoch_Clients[clientID], stepsValidate_Clients[clientID], stepsTest_Clients[clientID],\n",
    "                                     active_clients_list=active_clients_list)\n",
    "                 for clientID, client_name in enumerate(active_clients_list)}\n",
    "\n",
    "temp_dir_log = clientObjects['client_0'].get_temp_dir()\n",
    "for index, client_name in enumerate(active_clients_list):\n",
    "    clientObjects[client_name].get_steps_per_epoch()\n",
    "    clientObjects[client_name].get_validation_steps()\n",
    "    clientObjects[client_name].get_test_steps()\n",
    "\n",
    "agents_dict['server'] = serverObjects\n",
    "agents_dict['client'] = clientObjects\n",
    "\n",
    "for agent_name, agent in serverObjects.items():\n",
    "    agent.set_agentsDict(agents_dict=agents_dict)\n",
    "for agent_name, agent in clientObjects.items():\n",
    "    agent.set_agentsDict(agents_dict=agents_dict)\n",
    "\n",
    "# Giải phóng DataFrame sau khi không cần thiết\n",
    "del train_dfs, val_dfs, test_dfs\n",
    "\n",
    "server = agents_dict['server']['server_0']\n",
    "if __name__ == '__main__':\n",
    "    server.InitLoop()\n",
    "    server.final_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6170b44-a08a-42f6-bd1b-dd6fbfca9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#tempdirs = [f\"federated_learning_log/Month05-Day27-18h-56p/client_{i}_log/\" for i in range(len(active_clients_list))]\n",
    "tempdirs = [temp_dir_log + f\"/client_{i}_log/\" for i in range(len(active_clients_list))]\n",
    "\n",
    "model_names =[f\"global_model_iter_{i+1}.keras\" for i in range(4)]\n",
    "print(model_names)\n",
    "models = {}\n",
    "\n",
    "for i, client_name in enumerate(active_clients_list):\n",
    "    models[client_name] = [load_model(tempdirs[i]+model_name) for model_name in model_names]\n",
    "print (models['client_0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9902f253-9b8f-4465-9500-a6c90e708341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client 0\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "Iterations = [f\"Iteration {index+1}\" for index in range(4)]\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for X_batch, y_batch in test_gens[0].take(stepsTest_Clients[0]):\n",
    "    X_test.append(X_batch.numpy())\n",
    "    y_test.append(y_batch.numpy())\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "print(len(X_test))\n",
    "for iteration in range(len(Iterations)):\n",
    "    print(models['client_0'][iteration])\n",
    "    y_pred_pre = models['client_0'][iteration].predict(X_test, verbose=1)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    precisions.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recalls.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Precision Score: \", precisions)\n",
    "print(\"Recall Score: \", recalls)\n",
    "print(\"F1 Score: \", f1s)  \n",
    "\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(Iterations, precisions, marker='o', linestyle='-', label=\"Precision\", color='blue')\n",
    "plt.plot(Iterations, recalls, marker='s', linestyle='-', label=\"Recall\", color='red')\n",
    "plt.plot(Iterations, f1s, marker='^', linestyle='-', label=\"F1-score\", color='green')\n",
    "\n",
    "# Thêm tiêu đề và nhãn\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall, F1-score over different iterations _ CLIENT 0\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5, 1)  # Giới hạn từ 0 đến 1\n",
    "plt.grid(True)\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "attack_types =['Benign', 'DDos', 'Mirai', 'Spoofing', 'Reconnaissance']\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "    # Vẽ heatmap\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=attack_types, yticklabels=attack_types)\n",
    "plt.yticks(rotation=360)\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix CLIENT 0\")\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# Số lượng lớp (10 lớp)\n",
    "num_classes = len(attack_types)\n",
    "\n",
    "# Duyệt từng lớp để tính TP, FP, TN, FN\n",
    "for i in range(num_classes):\n",
    "    TP = cm[i, i]\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    \n",
    "    metrics.append([attack_types[i], TP, FP, TN, FN])\n",
    "\n",
    "# Chuyển thành DataFrame\n",
    "df_metrics = pd.DataFrame(metrics, columns=[\"Attack_Types\", \"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "df_metrics.set_index(\"Attack_Types\").plot(kind=\"bar\", figsize=(12, 5), colormap=\"viridis\")\n",
    "\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"TP, FP, TN, FN for Each Class CLIENT 0\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend([\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e8d9f-dcb9-46fd-8599-b6769a5d082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Client 1\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "Iterations = [f\"Iteration {index+1}\" for index in range(4)]\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for X_batch, y_batch in test_gens[1].take(stepsTest_Clients[1]):\n",
    "    X_test.append(X_batch.numpy())\n",
    "    y_test.append(y_batch.numpy())\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "print(len(X_test))\n",
    "for iteration in range(len(Iterations)):\n",
    "    print(models['client_1'][iteration])\n",
    "    y_pred_pre = models['client_1'][iteration].predict(X_test, verbose=1)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    precisions.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recalls.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Precision Score: \", precisions)\n",
    "print(\"Recall Score: \", recalls)\n",
    "print(\"F1 Score: \", f1s)  \n",
    "\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(Iterations, precisions, marker='o', linestyle='-', label=\"Precision\", color='blue')\n",
    "plt.plot(Iterations, recalls, marker='s', linestyle='-', label=\"Recall\", color='red')\n",
    "plt.plot(Iterations, f1s, marker='^', linestyle='-', label=\"F1-score\", color='green')\n",
    "\n",
    "# Thêm tiêu đề và nhãn\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall, F1-score over different iterations _ CLIENT 1\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5, 1)  # Giới hạn từ 0 đến 1\n",
    "plt.grid(True)\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "attack_types =['Benign', 'DDos', 'Mirai', 'Spoofing', 'Reconnaissance']\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "    # Vẽ heatmap\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=attack_types, yticklabels=attack_types)\n",
    "plt.yticks(rotation=360)\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix CLIENT 1\")\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# Số lượng lớp (10 lớp)\n",
    "num_classes = len(attack_types)\n",
    "\n",
    "# Duyệt từng lớp để tính TP, FP, TN, FN\n",
    "for i in range(num_classes):\n",
    "    TP = cm[i, i]\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    \n",
    "    metrics.append([attack_types[i], TP, FP, TN, FN])\n",
    "\n",
    "# Chuyển thành DataFrame\n",
    "df_metrics = pd.DataFrame(metrics, columns=[\"Attack_Types\", \"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "df_metrics.set_index(\"Attack_Types\").plot(kind=\"bar\", figsize=(12, 5), colormap=\"viridis\")\n",
    "\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"TP, FP, TN, FN for Each Class CLIENT 1\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend([\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587997af-c806-444c-b76a-cd277bdf8b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Client 2\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "Iterations = [f\"Iteration {index+1}\" for index in range(4)]\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for X_batch, y_batch in test_gens[2].take(stepsTest_Clients[2]):\n",
    "    X_test.append(X_batch.numpy())\n",
    "    y_test.append(y_batch.numpy())\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "print(len(X_test))\n",
    "for iteration in range(len(Iterations)):\n",
    "    print(models['client_2'][iteration])\n",
    "    y_pred_pre = models['client_2'][iteration].predict(X_test, verbose=1)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    precisions.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recalls.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Precision Score: \", precisions)\n",
    "print(\"Recall Score: \", recalls)\n",
    "print(\"F1 Score: \", f1s)  \n",
    "\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(Iterations, precisions, marker='o', linestyle='-', label=\"Precision\", color='blue')\n",
    "plt.plot(Iterations, recalls, marker='s', linestyle='-', label=\"Recall\", color='red')\n",
    "plt.plot(Iterations, f1s, marker='^', linestyle='-', label=\"F1-score\", color='green')\n",
    "\n",
    "# Thêm tiêu đề và nhãn\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall, F1-score over different iterations _ CLIENT 2\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5, 1)  # Giới hạn từ 0 đến 1\n",
    "plt.grid(True)\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "attack_types =['Benign', 'DDos', 'Mirai', 'Spoofing', 'Reconnaissance']\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "    # Vẽ heatmap\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=attack_types, yticklabels=attack_types)\n",
    "plt.yticks(rotation=360)\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix CLIENT 2\")\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# Số lượng lớp (10 lớp)\n",
    "num_classes = len(attack_types)\n",
    "\n",
    "# Duyệt từng lớp để tính TP, FP, TN, FN\n",
    "for i in range(num_classes):\n",
    "    TP = cm[i, i]\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    \n",
    "    metrics.append([attack_types[i], TP, FP, TN, FN])\n",
    "\n",
    "# Chuyển thành DataFrame\n",
    "df_metrics = pd.DataFrame(metrics, columns=[\"Attack_Types\", \"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "df_metrics.set_index(\"Attack_Types\").plot(kind=\"bar\", figsize=(12, 5), colormap=\"viridis\")\n",
    "\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"TP, FP, TN, FN for Each Class CLIENT 2\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend([\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366ede57-dc36-4bff-a138-946f3e43218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Giả định tempdirs đã được định nghĩa\n",
    "# Ví dụ: tempdirs = [f\"federated_learning_log/21h-04p-Month05-Day27/client_{i}_log/\" for i in range(4)]\n",
    "#tempdirs = [f\"federated_learning_log/Month05-Day27-18h-56p/client_{i}_log/\" for i in range(4)]  # 4 clients\n",
    "log_names = [f\"Iteration_{i+1}.csv\" for i in range(4)]\n",
    "print(log_names)\n",
    "\n",
    "# Vẽ biểu đồ cho từng client\n",
    "for i in range(3):\n",
    "    # Kết hợp dữ liệu từ các file log\n",
    "    all_logs = []\n",
    "    for log_name in log_names:\n",
    "        file_path = tempdirs[i] + log_name\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File {file_path} không tồn tại!\")\n",
    "            continue\n",
    "        log_part = pd.read_csv(file_path)\n",
    "        all_logs.append(log_part)\n",
    "\n",
    "    # Kết hợp dữ liệu từ các file log\n",
    "    log_df = pd.concat(all_logs, ignore_index=True)\n",
    "    epochs = range(1, len(log_df) + 1)  # Tổng cộng 20 epoch (4 iterations x 5 epochs)\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, log_df['accuracy'], 'b-', label='Training Accuracy')\n",
    "    # Thêm đường kẻ dọc tại epoch 5, 10, 15\n",
    "    for iter_idx in range(1, len(log_names)):\n",
    "        plt.axvline(x=iter_idx * 5, color='gray', linestyle='-', linewidth=2, alpha=0.9)\n",
    "        if iter_idx < len(log_names) - 1:  \n",
    "            plt.text(iter_idx * 5 - 2, 0.98, f'Iter {iter_idx}', rotation=0, verticalalignment='top', fontsize=10, fontweight='bold')\n",
    "        else:  # Iter 4\n",
    "            plt.text(iter_idx * 5 - 2, 0.98, f'Iter {iter_idx}         (Last Iteration)', rotation=0, verticalalignment='top', fontsize=10, fontweight='bold')\n",
    "    plt.title(f'Training Accuracy Client {i}')\n",
    "    plt.title(f'Training Accuracy Client {i}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.ylim(0.40, 1.0)\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, log_df['loss'], 'r-', label='Training Loss')\n",
    "    for iter_idx in range(1, len(log_names)):\n",
    "        plt.axvline(x=iter_idx * 5, color='gray', linestyle='-', linewidth=2, alpha=0.9)\n",
    "        if iter_idx < len(log_names) - 1:\n",
    "            plt.text(iter_idx * 5 - 2, max(log_df['loss']) * 0.95, f'Iter {iter_idx}', rotation=0, verticalalignment='top', fontsize=10, fontweight='bold')\n",
    "        else:\n",
    "            plt.text(iter_idx * 5 - 2, max(log_df['loss']) * 0.95, f'Iter {iter_idx}         (Last Iteration)', rotation=0, verticalalignment='top', fontsize=10, fontweight='bold')\n",
    "    plt.title(f'Training Loss Client {i}')\n",
    "    plt.title(f'Training Loss Client {i}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Validation Accuracy\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs, log_df['val_accuracy'], 'g-', label='Validation Accuracy')\n",
    "    for iter_idx in range(1, len(log_names)):\n",
    "        plt.axvline(x=iter_idx * 5, color='gray', linestyle='-', linewidth=2, alpha=0.9)\n",
    "        if iter_idx < len(log_names) - 1:\n",
    "            plt.text(iter_idx * 5 - 2, 0.998, f'Iter {iter_idx}', rotation=0, verticalalignment='top', fontsize=10, fontweight='bold')\n",
    "        else:\n",
    "            plt.text(iter_idx * 5 - 2, 0.998, f'Iter {iter_idx}         (Last Iteration)', rotation=0, verticalalignment='top', fontsize=10, fontweight='bold')\n",
    "    plt.title(f'Validation Accuracy Client {i}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.ylim(0.95, 1.0)\n",
    "\n",
    "    # Validation Loss\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(epochs, log_df['val_loss'], 'm-', label='Validation Loss')\n",
    "    for iter_idx in range(1, len(log_names)):\n",
    "        plt.axvline(x=iter_idx * 5, color='gray', linestyle='-', linewidth=2, alpha=0.9)\n",
    "        if iter_idx < len(log_names) - 1:\n",
    "            plt.text(iter_idx * 5 - 2, max(log_df['val_loss']) * 0.95, f'Iter {iter_idx}', rotation=0, verticalalignment='top', fontsize=10, fontweight='bold')\n",
    "        else:\n",
    "            plt.text(iter_idx * 5 - 2, max(log_df['val_loss']) * 0.95, f'Iter {iter_idx}         (Last Iteration)', rotation=0, verticalalignment='top', fontsize=10, fontweight='bold')\n",
    "    plt.title(f'Validation Loss Client {i}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de9130-d64a-4cd5-997c-91308d12abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Giả định tempdirs đã được định nghĩa\n",
    "# Ví dụ: tempdirs = [f\"federated_learning_log/21h-04p-Month05-Day27/client_{i}_log/\" for i in range(4)]\n",
    "#tempdirs = [f\"federated_learning_log/Month05-Day27-18h-56p/client_{i}_log/\" for i in range(4)]  # 4 clients\n",
    "Iterations = [f\"Iteration {index+1}\" for index in range(4)]\n",
    "\n",
    "# Vẽ biểu đồ cho từng client\n",
    "for i in range(3):\n",
    "    file_path_local = tempdirs[i] + \"local_val.csv\"\n",
    "    file_path_global = tempdirs[i] + \"global_val.csv\"\n",
    "  \n",
    "    local_val = pd.read_csv(file_path_local)\n",
    "    global_val = pd.read_csv(file_path_global)\n",
    "    # Vẽ biểu đồ\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(Iterations, local_val['local_acc'], marker='o', linestyle='-', label=\"Local Acc\", color='blue')\n",
    "    plt.plot(Iterations, global_val['global_acc'], marker='s', linestyle='-', label=\"Global Acc\", color='red')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(f\"Local and Global Evaluation Accuracy Client {i}\")\n",
    "    plt.legend()\n",
    "    #plt.ylim(0.5, 1)  # Giới hạn từ 0 đến 1\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(Iterations, local_val['local_loss'], marker='o', linestyle='-', label=\"Local Loss\", color='green')\n",
    "    plt.plot(Iterations, global_val['global_loss'], marker='s', linestyle='-', label=\"Global Loss\", color='purple')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(f\"Local and Global Evaluation Loss Client {i}\")\n",
    "    plt.legend()\n",
    "    #plt.ylim(0.5, 1)  # Giới hạn từ 0 đến 1\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Hiển thị đồ thị\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5ca3b1-1af0-4338-b89a-19167f40dbba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
